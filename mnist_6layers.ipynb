{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef30bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow官方程式碼\n",
    "#現階段大部分都用pytorch框架，因手寫辨識在早期以純熟，當時tensorflow應用較多，效率較高(快)，所以採用tensorflow，但現今可用pytorch改善損失率\n",
    "#ref: https://accandrew2.pixnet.net/blog/post/360741170-pytorch-%E8%88%87-tensorflow-%E6%AF%94%E8%BC%83\n",
    "\n",
    "\n",
    "import tensorflow as tf  #import tensorflow, 無論 CPU 或 GPU 版本都是 import tensorflow as tf\n",
    "\n",
    "#solve錯誤:Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c91009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras是tf的一個高階 API，用於建構及訓練深度學習模型\n",
    "\n",
    "mnist = tf.keras.datasets.mnist  #將MNIST 手寫數字資料讀進來\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # mnist 的load_data()會回傳已經先分割好的training data 和 testing data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0         # 將每個 pixel 從 Int 轉成 floating point 同時做normalize(常見的preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bfe81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train)) #training data 總共有60000張圖片\n",
    "print(x_train[0].shape) #每張圖片（拿第一張當樣本）大小為 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced9b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 28)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4732)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               605824    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "input_shape = (28, 28, 1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape)) #圖片沒超過128*128 kernel size(長寬)為奇數<=3\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "#model = tf.keras.models.Sequential([ # 開始搭建model 利用 \"Sequential\" 支援線性傳遞模型，把每層 layer 疊起來\n",
    "  #tf.keras.layers.Flatten(input_shape=(28, 28)),#把二維的手寫mnist展成一維(28*28=784)\n",
    "  #tf.keras.layers.Dense(128, activation='relu'), #dense設定神經元數量，加入激活函數使模型有非線性因素\n",
    "  #tf.keras.layers.Dropout(0.2), #每次訓練按概率20%拿走一部分神經元(每5個隨機輸入丟掉1個變量)，避免過適。剩下的神經元需補上消失的神經元功能，對同個問題有不同解法的集合。對每個神經元的變化不敏感，增加泛化能力\n",
    "  #tf.keras.layers.Dense(10, activation='softmax')#建立輸出層 數字0~9 有10個\n",
    "#])\n",
    "\n",
    "\n",
    "# model每層定義好後，在模型訓練之前要對模型用compile進行設定\n",
    "model.compile(optimizer='adam', #訓練時用的優化方法，adam最快收斂提高準確度\n",
    "              loss='sparse_categorical_crossentropy', #用來計算模型在訓練中要減少的量(模型權重的斜率)，loss函式有很多類別，此類別用於multi-classification，2個以上分類且label為int\n",
    "              metrics=['accuracy'])  #成效衡量指標\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4475421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1200/1200 [==============================] - 18s 14ms/step - loss: 0.2291 - accuracy: 0.9319\n",
      "Epoch 2/5\n",
      "1200/1200 [==============================] - 17s 14ms/step - loss: 0.0873 - accuracy: 0.9736\n",
      "Epoch 3/5\n",
      "1200/1200 [==============================] - 19s 16ms/step - loss: 0.0609 - accuracy: 0.9815\n",
      "Epoch 4/5\n",
      "1200/1200 [==============================] - 18s 15ms/step - loss: 0.0455 - accuracy: 0.9858\n",
      "Epoch 5/5\n",
      "1200/1200 [==============================] - 21s 17ms/step - loss: 0.0362 - accuracy: 0.9883\n",
      "313/313 - 2s - loss: 0.0621 - accuracy: 0.9831 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06213417276740074, 0.9830999970436096]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=model.fit(x_train, y_train, epochs=5, batch_size=50)      # 將搭好的 model 去 fit 我們的 training data\n",
    "model.evaluate(x_test, y_test, verbose=2)  # 並evalutate 在 testing data 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57458d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    plt.imshow(x_test[i+1].reshape(28, 28),cmap='Greys')\n",
    "    pred = model.predict(x_test[i+1].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())\n",
    "    \n",
    "#image_index = 666\n",
    "#plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "#pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "#print(pred.argmax())\n",
    "#model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
